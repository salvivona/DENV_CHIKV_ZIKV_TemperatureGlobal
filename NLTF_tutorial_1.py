import nltk

nltk.download()
'''
from nltk.tokenize import sent_tokenize, word_tokenize
#tokenizing - word tokenizers... sentence tokenizers
#lexicon and corporas
# corpora - body of text. ex: medical journals, presidential speeches, English language 
#lexicon - words and their means

example_text="hello mr.smith how are you doing today."
print(word_tokenize(example_text))
print(sent_tokenize(example_text))
'''